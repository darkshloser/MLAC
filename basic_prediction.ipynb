{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "229df0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "620d426f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# url = 'https://raw.githubusercontent.com/mwitiderrick/stockprice/master/NSE-TATAGLOBAL.csv'\n",
    "# dataset_train = pd.read_csv(url)\n",
    "# training_set = dataset_train.iloc[:, 1:2].values\n",
    "#See the yahoo finance ticker for your stock symbol\n",
    "stock_symbol = 'TATACONSUM.NS'\n",
    "dataset_train = yf.download(tickers=stock_symbol,period='5y',interval='1d')\n",
    "training_set = dataset_train.iloc[:, 1:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "32eb7cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[196.30000305],\n",
       "       [197.5       ],\n",
       "       [198.1499939 ],\n",
       "       ...,\n",
       "       [813.        ],\n",
       "       [811.90002441],\n",
       "       [810.79998779]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "158082ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>792.000000</td>\n",
       "      <td>795.000000</td>\n",
       "      <td>781.750000</td>\n",
       "      <td>788.099976</td>\n",
       "      <td>781.802673</td>\n",
       "      <td>1565651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>791.000000</td>\n",
       "      <td>810.000000</td>\n",
       "      <td>788.200012</td>\n",
       "      <td>806.650024</td>\n",
       "      <td>800.204529</td>\n",
       "      <td>2912280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>810.450012</td>\n",
       "      <td>812.500000</td>\n",
       "      <td>797.049988</td>\n",
       "      <td>809.250000</td>\n",
       "      <td>802.783691</td>\n",
       "      <td>2004175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>809.000000</td>\n",
       "      <td>818.299988</td>\n",
       "      <td>802.049988</td>\n",
       "      <td>804.900024</td>\n",
       "      <td>798.468506</td>\n",
       "      <td>1965237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-08</th>\n",
       "      <td>810.500000</td>\n",
       "      <td>819.849976</td>\n",
       "      <td>804.000000</td>\n",
       "      <td>817.700012</td>\n",
       "      <td>811.166199</td>\n",
       "      <td>1406219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-22</th>\n",
       "      <td>785.900024</td>\n",
       "      <td>796.950012</td>\n",
       "      <td>780.099976</td>\n",
       "      <td>793.950012</td>\n",
       "      <td>793.950012</td>\n",
       "      <td>2166778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-23</th>\n",
       "      <td>791.900024</td>\n",
       "      <td>811.650024</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>809.349976</td>\n",
       "      <td>809.349976</td>\n",
       "      <td>1890327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-24</th>\n",
       "      <td>805.000000</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>798.500000</td>\n",
       "      <td>805.700012</td>\n",
       "      <td>805.700012</td>\n",
       "      <td>1355374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-25</th>\n",
       "      <td>808.000000</td>\n",
       "      <td>811.900024</td>\n",
       "      <td>797.500000</td>\n",
       "      <td>801.849976</td>\n",
       "      <td>801.849976</td>\n",
       "      <td>1267482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-26</th>\n",
       "      <td>805.900024</td>\n",
       "      <td>810.799988</td>\n",
       "      <td>798.799988</td>\n",
       "      <td>801.950012</td>\n",
       "      <td>801.950012</td>\n",
       "      <td>1254230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2022-04-04  792.000000  795.000000  781.750000  788.099976  781.802673   \n",
       "2022-04-05  791.000000  810.000000  788.200012  806.650024  800.204529   \n",
       "2022-04-06  810.450012  812.500000  797.049988  809.250000  802.783691   \n",
       "2022-04-07  809.000000  818.299988  802.049988  804.900024  798.468506   \n",
       "2022-04-08  810.500000  819.849976  804.000000  817.700012  811.166199   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2022-08-22  785.900024  796.950012  780.099976  793.950012  793.950012   \n",
       "2022-08-23  791.900024  811.650024  787.000000  809.349976  809.349976   \n",
       "2022-08-24  805.000000  813.000000  798.500000  805.700012  805.700012   \n",
       "2022-08-25  808.000000  811.900024  797.500000  801.849976  801.849976   \n",
       "2022-08-26  805.900024  810.799988  798.799988  801.950012  801.950012   \n",
       "\n",
       "             Volume  \n",
       "Date                 \n",
       "2022-04-04  1565651  \n",
       "2022-04-05  2912280  \n",
       "2022-04-06  2004175  \n",
       "2022-04-07  1965237  \n",
       "2022-04-08  1406219  \n",
       "...             ...  \n",
       "2022-08-22  2166778  \n",
       "2022-08-23  1890327  \n",
       "2022-08-24  1355374  \n",
       "2022-08-25  1267482  \n",
       "2022-08-26  1254230  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6657217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(0,1))\n",
    "training_set_scaled = sc.fit_transform(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fd52bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0146515 ],\n",
       "       [0.01635846],\n",
       "       [0.01728306],\n",
       "       ...,\n",
       "       [0.89189189],\n",
       "       [0.8903272 ],\n",
       "       [0.88876243]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ae03fca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1278094 ],\n",
       "        [0.12937413],\n",
       "        [0.13371266],\n",
       "        ...,\n",
       "        [0.15305833],\n",
       "        [0.14295875],\n",
       "        [0.13904694]],\n",
       "\n",
       "       [[0.12937413],\n",
       "        [0.13371266],\n",
       "        [0.13143669],\n",
       "        ...,\n",
       "        [0.14295875],\n",
       "        [0.13904694],\n",
       "        [0.13790898]],\n",
       "\n",
       "       [[0.13371266],\n",
       "        [0.13143669],\n",
       "        [0.1476529 ],\n",
       "        ...,\n",
       "        [0.13904694],\n",
       "        [0.13790898],\n",
       "        [0.14061167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.86443814],\n",
       "        [0.87133711],\n",
       "        [0.8391181 ],\n",
       "        ...,\n",
       "        [0.86906118],\n",
       "        [0.88997159],\n",
       "        [0.89189189]],\n",
       "\n",
       "       [[0.87133711],\n",
       "        [0.8391181 ],\n",
       "        [0.84580366],\n",
       "        ...,\n",
       "        [0.88997159],\n",
       "        [0.89189189],\n",
       "        [0.8903272 ]],\n",
       "\n",
       "       [[0.8391181 ],\n",
       "        [0.84580366],\n",
       "        [0.86849216],\n",
       "        ...,\n",
       "        [0.89189189],\n",
       "        [0.8903272 ],\n",
       "        [0.88876243]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-10:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix:end_ix+10]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "n_steps = 60\n",
    "X_train, y_train = split_sequence(training_set_scaled, n_steps)\n",
    "\n",
    "# X_train.append(training_set_scaled[0:60, 0])\n",
    "# y_train.append(training_set_scaled[0, 0])\n",
    "\n",
    "# for i in range(60, 2035):\n",
    "#     print(i, training_set_scaled[i-60:i, 0], training_set_scaled[i, 0])\n",
    "# X_train.append(training_set_scaled[i-60:i, 0])\n",
    "# y_train.append(training_set_scaled[i, 0])\n",
    "# X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "# X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ddbc1f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 1\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], n_features))\n",
    "y_train = y_train.reshape((y_train.shape[0], y_train.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5993360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.1278094 ],\n",
       "        [0.12937413],\n",
       "        [0.13371266],\n",
       "        ...,\n",
       "        [0.15305833],\n",
       "        [0.14295875],\n",
       "        [0.13904694]],\n",
       "\n",
       "       [[0.12937413],\n",
       "        [0.13371266],\n",
       "        [0.13143669],\n",
       "        ...,\n",
       "        [0.14295875],\n",
       "        [0.13904694],\n",
       "        [0.13790898]],\n",
       "\n",
       "       [[0.13371266],\n",
       "        [0.13143669],\n",
       "        [0.1476529 ],\n",
       "        ...,\n",
       "        [0.13904694],\n",
       "        [0.13790898],\n",
       "        [0.14061167]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.86443814],\n",
       "        [0.87133711],\n",
       "        [0.8391181 ],\n",
       "        ...,\n",
       "        [0.86906118],\n",
       "        [0.88997159],\n",
       "        [0.89189189]],\n",
       "\n",
       "       [[0.87133711],\n",
       "        [0.8391181 ],\n",
       "        [0.84580366],\n",
       "        ...,\n",
       "        [0.88997159],\n",
       "        [0.89189189],\n",
       "        [0.8903272 ]],\n",
       "\n",
       "       [[0.8391181 ],\n",
       "        [0.84580366],\n",
       "        [0.86849216],\n",
       "        ...,\n",
       "        [0.89189189],\n",
       "        [0.8903272 ],\n",
       "        [0.88876243]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5e2bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8e7f40a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "37/37 [==============================] - 8s 77ms/step - loss: 0.0338\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0061\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0058\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0052\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0058\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 3s 88ms/step - loss: 0.0043\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0044\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0051\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0052\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0049\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0044\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0042\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0039\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.0041\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0040\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0034\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0036\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0040\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0038\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0034\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0039\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0037\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0036\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0033\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0033\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0031\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0037\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0032\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0030\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0031\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0031\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0030\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0029\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0033\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0033\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0027\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0031\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.0028\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0029\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0027\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0027\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0026\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0025\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0027\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0027\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0027\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0028\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0027\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0026\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0026\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0027\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0027\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0026\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 3s 82ms/step - loss: 0.0026\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0027\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0028\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0023\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0023\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0026\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0025\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0021\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0021\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0020\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0023\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0021\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0021\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0024\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0023\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0022\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0021\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0020\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0023\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0022\n",
      "Epoch 89/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0021\n",
      "Epoch 90/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0021\n",
      "Epoch 91/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0022\n",
      "Epoch 92/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0023\n",
      "Epoch 93/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0021\n",
      "Epoch 94/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0021\n",
      "Epoch 95/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0021\n",
      "Epoch 96/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.0021\n",
      "Epoch 97/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 0.0021\n",
      "Epoch 98/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0019\n",
      "Epoch 99/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0020\n",
      "Epoch 100/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0c87d59f40>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1], 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model.fit(X_train,y_train,epochs=100,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b3e8e",
   "metadata": {},
   "source": [
    "# Make test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39589345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bf89e4b",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1abaa386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last 60 days to predict the next 10\n",
    "latest_60_days = X_train[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0ecbcd56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_scaled_price = model.predict(latest_60_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "27340a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price = sc.inverse_transform(predicted_scaled_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c39002d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[801.8605 ],\n",
       "       [799.9056 ],\n",
       "       [799.86945],\n",
       "       [802.04114],\n",
       "       [803.1594 ],\n",
       "       [799.40875],\n",
       "       [791.2016 ],\n",
       "       [781.73706],\n",
       "       [774.1463 ],\n",
       "       [770.5756 ]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc6812",
   "metadata": {},
   "source": [
    "# Visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d21d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
